# 🧹 SQL Data Cleaning Project – Layoffs Data

Hi there! I'm **Abhay Gomkale* . This is a small project where I cleaned a messy dataset about layoffs using **pure SQL**.

I’ve done all the cleaning in **MySQL Workbench**, and this project helped me practice a lot of important SQL concepts like:

- Creating backup tables
- Using `ROW_NUMBER()` to find duplicates
- Deleting duplicate rows
- Standardizing values (`TRIM()`, `LIKE`, `UPDATE`)
- Converting date formats
- Filling missing values using joins

## 📁 Files in this Repo

- `data_cleaning_layoffs.sql`: My full SQL script with comments. It’s organized in the correct order for data cleaning from start to finish.
- (You can upload the raw CSV file here if you have it)

## 📊 Dataset Info

This dataset contains records of company layoffs across various industries, countries, and time periods. It includes columns like:

- `company`
- `location`
- `industry`
- `total_laid_off`
- `percentage_laid_off`
- `stage`
- `country`
- `date`
- `funds_raised_millions`

## 🚀 What I Learned

- How to approach messy real-world data step by step
- Writing queries that build on each other
- Importance of clean and standardized data
- Working with NULLs and empty strings

## 🛠️ How to Run

1. Import your CSV file as a table named `layoffs` in MySQL Workbench.
2. Copy and paste the SQL script (`data_cleaning_layoffs.sql`) into the editor.
3. Run the queries step by step to see the cleaning process in action.

## 💡 Open to Feedback!

This is my **first SQL data cleaning project**, and I know it's not perfect.  
If you're reading this and you're more experienced — I would **love your suggestions**! 🙏

You can:
- Fork this repo and improve my queries
- Open an issue to suggest better techniques
- Help me write better SQL or optimize queries

Every comment will teach me something new 💬

## 🔗 Connect with Me
📧 abhaygomkale0@gmail.com  
📍 Nagpur, India  

Thanks for visiting! 🌟  
