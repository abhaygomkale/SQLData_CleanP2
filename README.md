# ğŸ§¹ SQL Data Cleaning Project â€“ Layoffs Data

Hi there! I'm **Abhay Gomkale* . This is a small project where I cleaned a messy dataset about layoffs using **pure SQL**.

Iâ€™ve done all the cleaning in **MySQL Workbench**, and this project helped me practice a lot of important SQL concepts like:

- Creating backup tables
- Using `ROW_NUMBER()` to find duplicates
- Deleting duplicate rows
- Standardizing values (`TRIM()`, `LIKE`, `UPDATE`)
- Converting date formats
- Filling missing values using joins

## ğŸ“ Files in this Repo

- `data_cleaning_layoffs.sql`: My full SQL script with comments. Itâ€™s organized in the correct order for data cleaning from start to finish.
- (You can upload the raw CSV file here if you have it)

## ğŸ“Š Dataset Info

This dataset contains records of company layoffs across various industries, countries, and time periods. It includes columns like:

- `company`
- `location`
- `industry`
- `total_laid_off`
- `percentage_laid_off`
- `stage`
- `country`
- `date`
- `funds_raised_millions`

## ğŸš€ What I Learned

- How to approach messy real-world data step by step
- Writing queries that build on each other
- Importance of clean and standardized data
- Working with NULLs and empty strings

## ğŸ› ï¸ How to Run

1. Import your CSV file as a table named `layoffs` in MySQL Workbench.
2. Copy and paste the SQL script (`data_cleaning_layoffs.sql`) into the editor.
3. Run the queries step by step to see the cleaning process in action.

## ğŸ’¡ Open to Feedback!

This is my **first SQL data cleaning project**, and I know it's not perfect.  
If you're reading this and you're more experienced â€” I would **love your suggestions**! ğŸ™

You can:
- Fork this repo and improve my queries
- Open an issue to suggest better techniques
- Help me write better SQL or optimize queries

Every comment will teach me something new ğŸ’¬

## ğŸ”— Connect with Me
ğŸ“§ abhaygomkale0@gmail.com  
ğŸ“ Nagpur, India  

Thanks for visiting! ğŸŒŸ  
